{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def cal_Filter(x,y,radiusInside,radiusOutside,r,Filter):\n",
    "    if radiusInside <= r and r <= radiusOutside:\n",
    "        Filter[y][x] = 0\n",
    "    else:\n",
    "        Filter[y][x] = -1000000\n",
    "    \n",
    "    return Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit#(i4(i4,i4,i4,i4,u1[:,:],f8[:,:],u4,u4,u4,u4,i4))\n",
    "def cal_dilation(u,v,xu,yv,f,g,f_x,f_y,g_x,g_y,maxValue):\n",
    "    if 0 <= xu and xu<=f_x-1 and 0 <= yv and yv <= f_y-1: \n",
    "        if 0 <= u+int(g_x/2) and u+int(g_x/2) <= g_x and 0 <= v+int(g_y/2) and v+int(g_y/2) <= g_y:\n",
    "            #print(xu, yv, 'f:',f[yv][xu],'g:',g[v+int(g_y/2)][u+int(g_x/2)])\n",
    "            value = f[yv][xu] + g[v+int(g_y/2)][u+int(g_x/2)]\n",
    "            maxValue = max(maxValue, value)\n",
    "    \n",
    "    return maxValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diaOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit#(u4[:,:](u4[:],u4,u4,u4))\n",
    "def cal_diaOut(diaOut,x,y,maxValue):\n",
    "    diaOut[y][x] = maxValue\n",
    "    \n",
    "    return diaOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit#(u4[:,:](u4,u4))\n",
    "def createFilter(radiusOutside, radiusInside):\n",
    "    Filter = np.zeros((radiusOutside*2+1, radiusOutside*2+1))\n",
    "    Filter_x, Filter_y = len(Filter[0]), len(Filter)\n",
    "    for y in range(Filter_y):\n",
    "        for x in range(Filter_x):\n",
    "            u = x - Filter_x/2\n",
    "            v = y - Filter_y/2\n",
    "            r = math.sqrt(u*u+v*v)\n",
    "            \n",
    "            Filter = cal_Filter(x,y,radiusInside,radiusOutside,r,Filter)\n",
    "    \n",
    "    return Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dilation def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit#(u4[:,:](u4[:],u4[:]))\n",
    "def dilation(f, g):\n",
    "    f_x, f_y = len(f[0]), len(f)\n",
    "    g_x, g_y = len(g[0]), len(g)\n",
    "#    print(f_x, f_y)\n",
    "#    print(g_x, g_y)\n",
    "#    print(int(g_x/2),int(g_y/2))\n",
    "    diaOut = np.zeros((f_y, f_x))\n",
    "    for y in range(f_y):\n",
    "        for x in range(f_x):\n",
    "            maxValue = -1000000\n",
    "            for v in range(g_y):\n",
    "                v = v - int(g_y/2)\n",
    "                for u in range(g_x):\n",
    "                    u = u - int(g_x/2)\n",
    "                    xu = x + u\n",
    "                    yv = y + v\n",
    "                    maxValue = cal_dilation(u,v,xu,yv,f,g,f_x,f_y,g_x,g_y,maxValue)\n",
    "            diaOut = cal_diaOut(diaOut,x,y,maxValue)\n",
    "    \n",
    "    return diaOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_diff(x, y, ringImg, diskImg):\n",
    "    value = diskImg[y][x] - ringImg[y][x]\n",
    "    outImg[y][x] = value   \n",
    "            \n",
    "    return outImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要素消す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_list(seq):\n",
    "    seen = []\n",
    "    return [x for x in seq if x not in seen and not seen.append(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN用設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重みの読み込み\n",
    "weights_path = 'weight/ex12_100_area2回目.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 55, 55, 96)        11712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 128)       307328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              3201000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,957,098\n",
      "Trainable params: 4,957,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNNパラメータ設定\n",
    "classes = 2\n",
    "class_name = ['defect','other']\n",
    "ker = cv2.INTER_LINEAR\n",
    "input_size = 227\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#第一層Cov1\n",
    "model.add(\n",
    "        Conv2D(\n",
    "                filters = 96,\n",
    "                kernel_size = (11,11),\n",
    "                strides = (4,4),\n",
    "                padding = 'valid',\n",
    "                input_shape = (227,227,1),\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "#正則化\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#第二層Pool1\n",
    "model.add(\n",
    "        MaxPooling2D(pool_size=(3,3),\n",
    "                     strides = (2,2),\n",
    "                     padding = 'valid')\n",
    "        )\n",
    "        \n",
    "#第三層Cov2\n",
    "model.add(\n",
    "        Conv2D(\n",
    "                filters = 128,\n",
    "                kernel_size = (5,5),\n",
    "                strides = (1,1),\n",
    "                padding = 'valid',\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "\n",
    "#正則化\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#第四層Pool2\n",
    "model.add(\n",
    "        MaxPooling2D(pool_size=(3,3),\n",
    "                     strides = (2,2),\n",
    "                     padding = 'valid')\n",
    "        )\n",
    "        \n",
    "#第五層Cov3-1\n",
    "model.add(\n",
    "        Conv2D(\n",
    "                filters = 256,\n",
    "                kernel_size = (3,3),\n",
    "                strides = (1,1),\n",
    "                padding = 'same',\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "\n",
    "#第六層Cov3-2\n",
    "model.add(\n",
    "        Conv2D(\n",
    "                filters = 256,\n",
    "                kernel_size = (3,3),\n",
    "                strides = (1,1),\n",
    "                padding = 'same',\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "\n",
    "#第七層Cov3-3\n",
    "model.add(\n",
    "        Conv2D(\n",
    "                filters = 128,\n",
    "                kernel_size = (3,3),\n",
    "                strides = (1,1),\n",
    "                padding = 'same',\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "\n",
    "#第八層Pool3\n",
    "model.add(\n",
    "        MaxPooling2D(pool_size=(3,3),\n",
    "                     strides = (2,2),\n",
    "                     padding = 'valid')\n",
    "        )\n",
    "\n",
    "#Flatten層\n",
    "model.add(Flatten())\n",
    "        \n",
    "#第九層FC1\n",
    "model.add(\n",
    "        Dense(1000)\n",
    "        )\n",
    "\n",
    "\n",
    "#第十層FC2\n",
    "model.add(\n",
    "        Dense(256)\n",
    "        )    \n",
    " \n",
    "#出力\n",
    "model.add(\n",
    "        Dense(classes,\n",
    "              activation='softmax'))\n",
    "\n",
    "#Sequentialオブジェクトのコンパイル\n",
    "model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = SGD(lr=0.001,momentum=0.9,decay=0.00005),\n",
    "        metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "#モデルのサマリーを表示\n",
    "model.summary()\n",
    "\n",
    "#重みを読み込む\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測関数\n",
    "from keras. applications.vgg16 import preprocess_input\n",
    "\n",
    "def predict(img):\n",
    "    img = cv2.resize(img,(227,227),interpolation=ker)\n",
    "    x = np.array(img, dtype=np.float32)\n",
    "    x = x/255.\n",
    "    x = x[None,...]\n",
    "    x = preprocess_input(x)\n",
    "    x = x.reshape(1,input_size,input_size,1)\n",
    "    pred = model.predict(x,verbose = 0)\n",
    "    pred_label = class_name[np.argmax(pred)]\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegNet用設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_output(model, img, width, height, mc_num, cls_num): \n",
    "    preds = np.zeros((width,height,cls_num))\n",
    "    for i in range(mc_num):\n",
    "        out = model.predict_segmentation(inp=img)\n",
    "        preds = preds+np.eye(cls_num)[out]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls2img(pred_img,cls_n):\n",
    "    shape = pred_img.shape\n",
    "    max_cls = np.argmax(pred_img, axis = 2)\n",
    "    out = np.zeros((shape[0], shape[1], 3))\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            out[i, j] = cls_n[max_cls[i, j]]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_segmentation2.models.segnet\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各種パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dil = 3\n",
    "kernel = 2\n",
    "kernel_size = np.ones((kernel,kernel),np.uint8)\n",
    "#リングの内径\n",
    "ring = 1\n",
    "#ディスク半径\n",
    "disk = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dil_rev = 2\n",
    "kernel_rev = 2\n",
    "kernel_size_rev = np.ones((kernel_rev,kernel_rev),np.uint8)\n",
    "ring_rev = 1\n",
    "disk_rev = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "input_data = 'check_data'\n",
    "\n",
    "all_data = glob.glob('{}/*'.format(input_data))\n",
    "all_name = [os.path.basename(p) for p in all_data\n",
    "       if os.path.isfile(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoit_blue1-1_187.png_抽出された欠陥の数: 978\n",
      "CNN_blue1-1_187.png_抽出された欠陥の数: 32\n",
      "quoit_black1-1_310.png_抽出された欠陥の数: 1109\n",
      "CNN_black1-1_310.png_抽出された欠陥の数: 82\n",
      "quoit_black1-3_741.png_抽出された欠陥の数: 998\n",
      "CNN_black1-3_741.png_抽出された欠陥の数: 54\n",
      "quoit_blue1-2_328.png_抽出された欠陥の数: 1018\n",
      "CNN_blue1-2_328.png_抽出された欠陥の数: 42\n",
      "経過時間：282.66994547843933\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 処理前の時刻\n",
    "t1 = time.time() \n",
    "\n",
    "#欠陥数出力リスト\n",
    "defect_num = []\n",
    "\n",
    "#input画像準備\n",
    "\n",
    "count_name = 0\n",
    "\n",
    "for img_path in all_data: \n",
    "    name = all_name[count_name]\n",
    "\n",
    "    \n",
    "    #画像読み込み\n",
    "    img_color = cv2.imread(img_path)\n",
    "    img_contour = cv2.imread(img_path)\n",
    "    img_quoit = cv2.imread(img_path)\n",
    "    img_CNN = cv2.imread(img_path)\n",
    "    img_CNN_cut = cv2.imread(img_path)\n",
    "    \n",
    "    color = cv2.imread(img_path)\n",
    "    #グレースケール\n",
    "    img = cv2.imread(img_path,0)\n",
    "    #height,width\n",
    "    h,w = img.shape[:2]\n",
    "    \n",
    "    #dilation処理\n",
    "    for i in range(dil):\n",
    "        #最初はimg読み込み\n",
    "        if i == 0:\n",
    "            d_img = cv2.dilate(img,kernel_size,iterations = 1)\n",
    "        #2回目以降はd_imgを読み込み\n",
    "        else:\n",
    "            d_img = cv2.dilate(d_img,kernel_size,iterations = 1)\n",
    "    d_img = cv2.resize(d_img,(480, 270))\n",
    "    \n",
    "    \n",
    "    #反転用\n",
    "    img_rev = cv2.bitwise_not(img)\n",
    "    for i in range(dil_rev):\n",
    "        if i == 0:\n",
    "            d_img_rev = cv2.dilate(img_rev,kernel_size_rev,iterations = 1)\n",
    "        else:\n",
    "            d_img_rev = cv2.dilate(d_img_rev,kernel_size_rev,iterations = 1)\n",
    "    d_img_rev = cv2.resize(d_img_rev,(480, 270))\n",
    "    \n",
    "    \n",
    "    ### quoit実装\n",
    "    \n",
    "    \n",
    "    #初期値設定\n",
    "    R1 = disk #Disk外径\n",
    "    R2 = ring #Ring内径\n",
    "    R3 = disk #Ring外径\n",
    "\n",
    "    #画像の読み込み\n",
    "    inImg = d_img\n",
    "    inImgSM = inImg\n",
    "\n",
    "    #フィルタ作成\n",
    "    diskFilter = createFilter(R1, 0)\n",
    "    ringFilter = createFilter(R3, R2)\n",
    "    #print('フィルタは起動している')\n",
    "\n",
    "    #Dilation画像を求める\n",
    "    diskImg = dilation(inImgSM, diskFilter)\n",
    "    ringImg = dilation(inImgSM, ringFilter)\n",
    "    #差分を計算し、出力画像用の配列を用意\n",
    "    #出力用の画像を用意\n",
    "    img_x, img_y = len(d_img[0]), len(d_img)\n",
    "    outImg = np.zeros((img_y, img_x))\n",
    "    #両画像の差分を求める\n",
    "    for y in range(img_y):\n",
    "        for x in range(img_x):\n",
    "            outImg = cal_diff(x, y, ringImg, diskImg)\n",
    "    outImg = cv2.resize(outImg,(w, h))\n",
    "    #輪郭取得&重心取得\n",
    "    #グレースケール画像\n",
    "    imageGRAY = outImg\n",
    "    blur = imageGRAY\n",
    "    #閾値で二値化する\n",
    "    threshold = 0.01\n",
    "    ret1, th1 = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)\n",
    "    #データ型を直す\n",
    "    th1 = th1.astype(np.uint8)\n",
    "\n",
    "    #輪郭を抽出する\n",
    "    contours, _ = cv2.findContours(th1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    dic = []\n",
    "    for i in contours :\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for n in i :\n",
    "            x += n[0][0]\n",
    "            y += n[0][1]\n",
    "        x = int(x/len(i))\n",
    "        y = int(y/len(i))\n",
    "        dic.append([[y-50,y+50,x-50,x+50],i])\n",
    "\n",
    "    #矩形と集合のリスト化\n",
    "    dic = np.array(dic)\n",
    "        \n",
    "        \n",
    "    ### 反転用\n",
    "\n",
    "    #初期値設定\n",
    "    R1 = disk_rev #Disk外径\n",
    "    R2 = ring_rev #Ring内径\n",
    "    R3 = disk_rev #Ring外径\n",
    "    #画像の読み込み\n",
    "    inImg = d_img_rev\n",
    "    inImgSM = inImg\n",
    "\n",
    "    #フィルタ作成\n",
    "    diskFilter = createFilter(R1, 0)\n",
    "    ringFilter = createFilter(R3, R2)\n",
    "    #print('フィルタは起動している')\n",
    "\n",
    "    #Dilation画像を求める\n",
    "    diskImg = dilation(inImgSM, diskFilter)\n",
    "    ringImg = dilation(inImgSM, ringFilter)\n",
    "    #差分を計算し、出力画像用の配列を用意\n",
    "    #出力用の画像を用意\n",
    "    img_x, img_y = len(d_img[0]), len(d_img)\n",
    "    outImg = np.zeros((img_y, img_x))\n",
    "    #両画像の差分を求める\n",
    "    for y in range(img_y):\n",
    "        for x in range(img_x):\n",
    "            outImg = cal_diff(x, y, ringImg, diskImg)\n",
    "    outImg = cv2.resize(outImg,(w, h))\n",
    "    #輪郭取得&重心取得\n",
    "    #グレースケール画像\n",
    "    imageGRAY = outImg\n",
    "    blur = imageGRAY\n",
    "    #閾値で二値化する\n",
    "    threshold = 0.01\n",
    "    ret1, th1 = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)\n",
    "    #データ型を直す\n",
    "    th1 = th1.astype(np.uint8)\n",
    "\n",
    "    #輪郭を抽出する\n",
    "    contours, _ = cv2.findContours(th1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    dic_rev = []\n",
    "    for i in contours :\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for n in i :\n",
    "            x += n[0][0]\n",
    "            y += n[0][1]\n",
    "        x = int(x/len(i))\n",
    "        y = int(y/len(i))\n",
    "        dic_rev.append([[y-50,y+50,x-50,x+50],i])\n",
    "    #矩形と集合のリスト化\n",
    "    dic_rev = np.array(dic_rev)\n",
    "    \n",
    "    \n",
    "    #領域と輪郭を配列にまとめる\n",
    "\n",
    "    def_loc = []\n",
    "    def_con = []\n",
    "\n",
    "    for loc,con in dic:\n",
    "        def_loc.append(loc)\n",
    "        def_con.append(con)\n",
    "    for loc,con in dic_rev:\n",
    "        def_loc.append(loc)\n",
    "        def_con.append(con)\n",
    "        \n",
    "    \n",
    "    #被りがあったら削除\n",
    "\n",
    "    def_loc = get_unique_list(def_loc)\n",
    "    \n",
    "    #quoit絞り込み\n",
    "    print(\"quoit_{}_抽出された欠陥の数:\".format(name), len(def_loc))\n",
    "    \n",
    "    \n",
    "    #Contour画像\n",
    "    cv2.drawContours(img_contour, contours, -1, color=(255, 0, 0), thickness=1)\n",
    "    cv2.imwrite('output_data/Contour/Contour_{}'.format(name), img_contour)\n",
    "    \n",
    "    #欠陥領域描写\n",
    "\n",
    "    for loc in def_loc:\n",
    "        if loc[0] < 0:\n",
    "            loc[0] = 0\n",
    "        if loc[2] < 0:\n",
    "            loc[2] = 0\n",
    "\n",
    "    for i, loc in enumerate(def_loc):\n",
    "        if i == 0:\n",
    "            #検出領域を四角で囲んで保存\n",
    "            result = img_quoit\n",
    "            result1 = cv2.rectangle(result,(loc[2],loc[0]), (loc[3],loc[1]), (255, 0, 0), 2)\n",
    "\n",
    "        if i != 0:\n",
    "            #検出領域を四角で囲んで保存\n",
    "            result = result1\n",
    "            result1 = cv2.rectangle(result, (loc[2], loc[0]), (loc[3], loc[1]), (255, 0, 0), 2)\n",
    "            \n",
    "    #保存\n",
    "    cv2.imwrite('output_data/quoit/quoit_{}'.format(name), result1) \n",
    "    \n",
    "    \n",
    "    #CNN適用\n",
    "\n",
    "    pred_loc = []\n",
    "\n",
    "    for loc in def_loc:\n",
    "        \n",
    "        cut = img[loc[0]:loc[1],loc[2]:loc[3]]\n",
    "        #print(loc,cut)\n",
    "        pred_label = predict(cut)\n",
    "        #print(pred_label)\n",
    "        if pred_label == 'defect':\n",
    "            pred_loc.append(loc)\n",
    "            \n",
    "    #CNN絞り込み\n",
    "    print(\"CNN_{}_抽出された欠陥の数:\".format(name), len(pred_loc))\n",
    "    \n",
    "    \n",
    "    for i, loc in enumerate(pred_loc):\n",
    "        if i == 0:\n",
    "            #検出領域を四角で囲んで保存\n",
    "            cnn_result = img_CNN\n",
    "            cnn_result1 = cv2.rectangle(cnn_result,(loc[2],loc[0]), (loc[3],loc[1]), (255, 0, 0), 2)\n",
    "        \n",
    "        if i != 0:\n",
    "            #検出領域を四角で囲んで保存\n",
    "            cnn_result = cnn_result1\n",
    "            cnn_result1 = cv2.rectangle(cnn_result, (loc[2], loc[0]), (loc[3], loc[1]), (255, 0, 0), 2)\n",
    "            \n",
    "    #保存\n",
    "    cv2.imwrite('output_data/CNN/CNN_{}'.format(name), cnn_result1)\n",
    "    \n",
    "    #CNNcut用のdir作成\n",
    "    dir_path = 'output_data/CNN_cut/{}'.format(name[0:-4])\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    #CNNcut保存\n",
    "    cut_n = 0\n",
    "    for loc in pred_loc:\n",
    "\n",
    "        CNN_cut = img_CNN_cut[loc[0]:loc[1], loc[2]:loc[3]]\n",
    "\n",
    "        cv2.imwrite('{}/CNN_cut_{}_{}'.format(dir_path, cut_n, name), CNN_cut)\n",
    "\n",
    "        cut_n += 1\n",
    "    \n",
    "    \n",
    "    #CNN_cut座標\n",
    "    df = pd.DataFrame(pred_loc)\n",
    "    df.columns = ['top', 'bottom', 'left', 'right']\n",
    "    \n",
    "    #書き出し\n",
    "    df.to_csv('{}/{}_CNN_cut_cordinates.csv'.format(dir_path, name[0:-4]), mode='w')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###SegNet\n",
    "    \n",
    "    cls = OrderedDict() #順序づき辞書\n",
    "    #色と欠点種別の対応\n",
    "    cls = {\"背景\":[0,0,0], \"欠陥\":[255,0,0]}\n",
    "    #色とインデックスの対応\n",
    "    cls_n = [[0,0,0],[255,0,0]]  \n",
    "\n",
    "    my_bayesSeg = keras_segmentation2.models.segnet.my_bayes_segnet(n_classes = 2,\n",
    "                                                                input_height = 384,\n",
    "                                                                input_width = 384,\n",
    "                                                                encoder_level = 3,\n",
    "                                                                dropout_rate = 0.02)\n",
    "    my_bayesSeg.load_weights('weight/seg_weight01_20_22_23.h5')\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    #SegNet_cut用のdir作成\n",
    "    \n",
    "    dir_path1 = 'output_data/SegNet_cut/{}'.format(name[0:-4])\n",
    "    os.makedirs(dir_path1, exist_ok=True)\n",
    "    \n",
    "    cut_n = 0\n",
    "    \n",
    "    #SegNet座標リスト\n",
    "    SegNet_list = []\n",
    "    SegNet_cut_list = []\n",
    "    \n",
    "    blank = np.zeros((2160,3840,3))\n",
    "    for loc in pred_loc:\n",
    "        \n",
    "        SegNet_check = 0\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            #矩形情報から図形の中心を求める\n",
    "            y = loc[0]+50\n",
    "            x = loc[2]+50\n",
    "\n",
    "            inp = color[y-192:y+192,x-192:x+192]\n",
    "            inp = cv2.resize(inp,(384,384))\n",
    "            out = mc_output(my_bayesSeg, inp,192,192,1,2)\n",
    "            out = cls2img(out, cls_n)\n",
    "            #cv2.imwrite('mask_'+str(count)+'.png',out)\n",
    "            #print(out.shape)\n",
    "            out = cv2.resize(out,(384,384))\n",
    "\n",
    "\n",
    "\n",
    "            #取れた領域の中央100ピクセル四方で囲まれた領域に出た出力のみオリジナル画像に描画していく\n",
    "\n",
    "            for j in range(142,243):\n",
    "                for i in range(142,243):\n",
    "                    #print(i,j)\n",
    "                    if out[j][i][0]+out[j][i][1]+out[j][i][2] != 0:\n",
    "                        img_color[y-192+j][x-192+i] = [0,0,255]\n",
    "                        blank[y-192+j][x-192+i] = [0,0,255]\n",
    "                        SegNet_check += 1\n",
    "                        SegNet_list.append([cut_n, (y-192+j), (x-192+i)])\n",
    "                        \n",
    "\n",
    "        except:\n",
    "            #print(x,y)\n",
    "\n",
    "            continue\n",
    "\n",
    "        img_color = np.array(img_color)\n",
    "        mask = np.array(blank)\n",
    "        \n",
    "        \n",
    "        #SegNet_cut保存\n",
    "        if SegNet_check > 0:\n",
    "            SegNet_cut_list.append([loc[0], loc[1], loc[2], loc[3]])\n",
    "            SegNet_cut = img_color[loc[0]:loc[1], loc[2]:loc[3]]\n",
    "            cv2.imwrite('{}/SegNet_cut_{}_{}'.format(dir_path1, cut_n, name), SegNet_cut)\n",
    "            cut_n += 1\n",
    "          \n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    #SegNet_list_csv, SegNet_cut_list_csv\n",
    "    df = pd.DataFrame(SegNet_list)\n",
    "    df.columns = ['cut_number', 'y', 'x']\n",
    "    \n",
    "    df1 = pd.DataFrame(SegNet_cut_list)\n",
    "    df1.columns = ['top', 'bottom', 'left', 'right']\n",
    "    \n",
    "    #書き出し\n",
    "    df.to_csv('{}/{}_SegNet.csv'.format(dir_path1, name[0:-4]), mode='w')\n",
    "    df1.to_csv('{}/{}_SegNet_cut_cordinates.csv'.format(dir_path1, name[0:-4]), mode='w')\n",
    "    \n",
    "    img_color = np.array(img_color)\n",
    "\n",
    "    cv2.imwrite('output_data/SegNet/SegNet_{}'.format(name),img_color)\n",
    "    cv2.imwrite('output_data/SegNet/mask_{}'.format(name),mask) \n",
    "    \n",
    "    count_name += 1\n",
    "    \n",
    "    defect_num.append([name, len(def_loc), len(pred_loc), len(SegNet_cut_list)])\n",
    "    \n",
    "\n",
    "#defect_num_csv    \n",
    "df = pd.DataFrame(defect_num)\n",
    "df.columns = ['画像ファイル名', 'quoit', 'CNN', 'SegNet']\n",
    "df.to_csv('output_data/defect_num_{}.csv'.format(input_data))\n",
    "\n",
    "# 処理後の時刻\n",
    "t2 = time.time()\n",
    " \n",
    "# 経過時間を表示\n",
    "elapsed_time = t2-t1\n",
    "print(f\"経過時間：{elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
